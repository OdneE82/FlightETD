{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7974505,"sourceType":"datasetVersion","datasetId":4692825}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Learning","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport pandas as pd, numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom datetime import datetime\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/cln-flr-bgo-csv/CLN_FLR_BGO_21_24.csv',delimiter=';')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dep_only_df = df[df['Dep'] == 1]\n# Dropping columns that are not needed.\ncolumns_to_drop = ['Arr', 'Flight In', 'STA', 'ATA',]\ncleaned_df = dep_only_df.drop(columns=columns_to_drop)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df['Date'] = pd.to_datetime(cleaned_df['Date'], format='%d/%m/%Y')\ncleaned_df['STD'] = pd.to_datetime(cleaned_df['STD'], format='%H:%M').dt.time\ncleaned_df['ATD'] = pd.to_datetime(cleaned_df['ATD'], format='%H:%M').dt.time\ncleaned_df['DayOfWeek'] = cleaned_df['Date'].dt.dayofweek\ncleaned_df['Month'] = cleaned_df['Date'].dt.month\ncleaned_df['STD_Minutes'] = cleaned_df['STD'].apply(lambda x: x.hour * 60 + x.minute)\ncleaned_df['ATD_Minutes'] = cleaned_df['ATD'].apply(lambda x: x.hour * 60 + x.minute)\ncleaned_df = cleaned_df.drop('Origin', axis=1)\ncleaned_df = cleaned_df.drop('Delay Code / Time', axis=1)\ncleaned_df['Flight Out'] = cleaned_df['Flight Out'].str.replace('WF','')\ncleaned_df['Aircraft Type'] = cleaned_df['Aircraft Type'].str.replace('DH','')\ncleaned_df['Aircraft Type'] = cleaned_df['Aircraft Type'].str.replace('AT','')\ncleaned_df = cleaned_df.dropna()\n# Verify the operation by checking for NaN values again\nprint(cleaned_df.isna().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cleaned_df.dtypes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For destination\nle_destination = LabelEncoder()\ncleaned_df['Destination'] = le_destination.fit_transform(cleaned_df['Destination'])\n\n# Extracting the mapping\ndestination_mapping = dict(zip(le_destination.classes_, le_destination.transform(le_destination.classes_)))\ndestination_mapping_df = pd.DataFrame(list(destination_mapping.items()), columns=['Destination', 'Encoded_Value'])\n\n# For aircraft reg\nle_aircraft_reg = LabelEncoder()\ncleaned_df['Aircraft Reg'] = le_aircraft_reg.fit_transform(cleaned_df['Aircraft Reg'])\n\n# Extracting the mapping\naircraft_reg_mapping = dict(zip(le_aircraft_reg.classes_, le_aircraft_reg.transform(le_aircraft_reg.classes_)))\naircraft_reg_mapping_df = pd.DataFrame(list(aircraft_reg_mapping.items()), columns=['Aircraft Reg', 'Encoded_Value'])\n\nprint(destination_mapping_df)\nprint(aircraft_reg_mapping_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_aircraft_types = cleaned_df['Aircraft Type'].unique()\nprint(unique_aircraft_types)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Dash8-100 = 1\n* Dash8-200 = 2\n* Dash8-300 = 3\n* Dash8-400 = 4\n* Embraer E2 = 290\n* ATR72 = 7","metadata":{}},{"cell_type":"code","source":"X = cleaned_df.drop(['ATD_Minutes', 'ATD','STD', 'Date'], axis=1)  # Adjust according to the final set of features\ny = cleaned_df['ATD_Minutes']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators=100, random_state = 42)\nrf.fit(X_train, y_train)\n\npredictions = rf.predict(X_test)\n\nmae = mean_absolute_error(y_test, predictions)\nmse = mean_squared_error(y_test, predictions)\nrmse= mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\nprint(\"Mean Squared Error:\", mse)\nprint(\"Root mean squared error:\", rmse)\nprint(\"R2-score\", r2)\nprint(\"Mean Absolute Error:\", mae)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot of actual vs predicted values\nplt.figure(figsize=(10, 6))\nplt.scatter(y_test, predictions, color='blue', alpha=0.5)  # Actual vs Predicted\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)  # Perfect predictions line\nplt.title('Actual vs Predicted Values')\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances = rf.feature_importances_\nfeatures = X.columns\nplt.bar(features, importances)\nplt.xticks(rotation=90)\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.title('Feature Importances')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering:\n\nAdding a time of day feature (Morning, Afternoon, Evening, Night)\n\nAdding a holiday feature (Christmas, Easter, Summer vacation etc..)\n\nAdding a season feature (Winter, Spring, Summer, Autumn)","metadata":{}},{"cell_type":"code","source":"cleaned_df['STD'] = pd.to_datetime(cleaned_df['STD'], format='%H:%M:%S')\ncleaned_df['STD_hour'] = cleaned_df['STD'].dt.hour\n\ndef get_time_of_day(hour):\n    if 5 <= hour < 12:\n        return 'Morning'\n    elif 12 <= hour < 17:\n        return 'Afternoon'\n    elif 17 <= hour < 21:\n        return 'Evening'\n    else:\n        return 'Night'\n    \ncleaned_df['TimeOfDay'] = cleaned_df['STD_hour'].apply(get_time_of_day)\ncleaned_df['STD'] = pd.to_datetime(cleaned_df['STD'], format='%H:%M').dt.time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_season(date_obj):\n    month = date_obj.month\n    if 3 <= month < 6:\n        return 'Spring'\n    elif 6 <= month < 9:\n        return 'Summer'\n    elif 9 <= month < 12:\n        return 'Autumn'\n    else:\n        return 'Winter'\n    \ncleaned_df['Season'] = cleaned_df['Date'].apply(get_season)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identify_holiday(week_of_year, year):\n    if (week_of_year >= 50 and year == 2021) or (week_of_year <= 1 and year == 2022):\n        return 'Christmas_Holidays'\n    elif (week_of_year >= 50 and year == 2022) or (week_of_year <= 1 and year == 2023):\n        return 'Christmas_Holidays'\n    elif (week_of_year >= 50 and year == 2023) or (week_of_year <= 1 and year == 2024):\n        return 'Christmas_Holidays'\n    elif 8 <= week_of_year <= 9:\n        return 'Winter_Holiday'\n    elif 11 <= week_of_year <= 13:\n        return 'Easter_Holiday'\n    elif 28 <= week_of_year <= 30:\n        return 'Summer_Vacation'\n    elif 40 <= week_of_year <= 41:\n        return 'Autumn_Vacation'\n    else:\n        return 'Regular'\n\n# Apply the function to each row in your dataframe to create a new 'Holiday' column\n# Assuming cleaned_df has a 'Date' column of dtype datetime64[ns]\ncleaned_df['WeekOfYear'] = cleaned_df['Date'].dt.isocalendar().week\ncleaned_df['Year'] = cleaned_df['Date'].dt.year\ncleaned_df['Holiday'] = cleaned_df.apply(lambda row: identify_holiday(row['WeekOfYear'], row['Year']), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df = cleaned_df.drop(['Date', 'Dep', 'DayOfWeek', 'Month', 'STD_hour', 'WeekOfYear', 'Year'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One-hot encode categorical variables\ncleaned_df = pd.get_dummies(cleaned_df, columns=['TimeOfDay', 'Season', 'Holiday'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define features and target variable\nselected_columns = ['Flight Out', 'Destination', \n                    'Aircraft Type', 'Aircraft Reg', 'STD_Minutes', \n                    'ATD_Minutes', 'TimeOfDay_Afternoon', 'TimeOfDay_Evening',\n                    'TimeOfDay_Morning', 'TimeOfDay_Night',\n                    'Season_Autumn', 'Season_Spring', 'Season_Summer',\n                    'Season_Winter', 'Holiday_Autumn_Vacation',\n                    'Holiday_Christmas_Holidays', 'Holiday_Easter_Holiday',\n                    'Holiday_Regular', 'Holiday_Summer_Vacation', 'Holiday_Winter_Holiday']\nX = cleaned_df[selected_columns].drop(['ATD_Minutes'], axis=1)  # Features\ny = cleaned_df['ATD_Minutes']  # Target variable\n\n# Perform train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initialize RandomForestRegressor model\nmodel = RandomForestRegressor(random_state=42)\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Predict on the test set\npredictions = model.predict(X_test)\n\nmae = mean_absolute_error(y_test, predictions)\nmse = mean_squared_error(y_test, predictions)\nrmse= mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\nprint(\"Mean Squared Error:\", mse)\nprint(\"Root mean squared error:\", rmse)\nprint(\"R2-score\", r2)\nprint(\"Mean Absolute Error:\", mae)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.inspection import permutation_importance\n\n# Scatter plot of actual vs predicted values\nplt.figure(figsize=(10, 6))\nplt.scatter(y_test, predictions, color='blue', alpha=0.5)  # Actual vs Predicted\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)  # Perfect predictions line\nplt.title('Actual vs Predicted Values')\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.show()\n\n# Feature importance plot\nresult = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\nsorted_idx = result.importances_mean.argsort()\n\nplt.figure(figsize=(10, 8))\nplt.barh(X.columns[sorted_idx], result.importances_mean[sorted_idx])\nplt.xlabel('Permutation Importance')\nplt.title('Feature Importance')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Saving the model.","metadata":{}},{"cell_type":"code","source":"import pickle\n\n# Save the model to a file\nwith open('random_forest_model.pkl', 'wb') as f:\n    pickle.dump(model, f)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deep Learning","metadata":{}},{"cell_type":"code","source":"pip install fastai","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dlf = pd.read_csv('/kaggle/input/cln-flr-bgo-csv/CLN_FLR_BGO_21_24.csv',delimiter=';')\ndlf.drop(['Arr','Flight In', 'Dep','Origin','STA','ATA','Delay Code / Time'], axis=1, inplace=True)\ndlf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def time_to_minutes(time_str):\n    if pd.isna(time_str):\n        return None\n    hours, minutes = map(int, time_str.split(':'))\n    return hours * 60 + minutes\n\ndlf['STD_Minutes'] = dlf['STD'].apply(time_to_minutes)\ndlf['ATD_Minutes'] = dlf['ATD'].apply(time_to_minutes)\n\ndlf.dropna(subset=['ATD_Minutes'], inplace=True)\n\ndlf['Date'] = pd.to_datetime(dlf['Date'], format='%d/%m/%Y')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dlf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.tabular.all import *\n\n# Define categorical and continuous columns\ncategorical_cols = ['Flight Out', 'Destination', 'Aircraft Type', 'Aircraft Reg']\ncontinuous_cols = ['STD_Minutes']\ny_names = 'ATD_Minutes'\n\n# Process the data\nsplits = RandomSplitter(valid_pct=0.2, seed=42)(range_of(dlf))\nprocs = [Categorify, FillMissing, Normalize]\nto = TabularPandas(dlf, procs=procs,\n                   cat_names=categorical_cols,\n                   cont_names=continuous_cols,\n                   y_names=y_names,\n                   y_block=RegressionBlock(),\n                   splits=splits)\n\ndls = to.dataloaders(bs=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn = tabular_learner(dls, metrics=rmse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.fit_one_cycle(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds,targs = learn.get_preds()\n\nmae = mean_absolute_error(targs, preds)\nmse = mean_squared_error(targs, preds)\nrmse= mean_squared_error(targs, preds, squared=False)\nr2 = r2_score(targs, preds)\n\nprint(\"Mean Squared Error:\", mse)\nprint(\"Root mean squared error:\", rmse)\nprint(\"R2-score\", r2)\nprint(\"Mean Absolute Error:\", mae)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.show_results()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot of actual vs predicted values\nplt.figure(figsize=(10, 6))\nplt.scatter(targs, preds, color='blue', alpha=0.5)  # Actual vs Predicted\nplt.plot([targs.min(), targs.max()], [targs.min(), targs.max()], color='red', linewidth=2)  # Perfect predictions line\nplt.title('Actual vs Predicted Values')\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}